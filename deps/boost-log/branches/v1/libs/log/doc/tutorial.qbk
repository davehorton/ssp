[/
              Copyright Andrey Semashev 2007 - 2010.
     Distributed under the Boost Software License, Version 1.0.
        (See accompanying file LICENSE_1_0.txt or copy at
              http://www.boost.org/LICENSE_1_0.txt)

    This document is a part of Boost.Log library documentation.
/]

[section:tutorial Tutorial]

In this section we shall walk through the essential steps to get started with the library. After reading it you should be able to initialize the library and add logging to your application. The code of this tutorial is also available in examples residing in the `libs/log/examples` directory. Feel free to play around with them, compile and see the result.

[section:trivial Trivial logging]

For those who don't want to read tons of clever manuals and just need a simple tool for logging, here you go:

    #include <boost/log/trivial.hpp>

    int main(int, char*[])
    {
        BOOST_LOG_TRIVIAL(trace) << "A trace severity message";
        BOOST_LOG_TRIVIAL(debug) << "A debug severity message";
        BOOST_LOG_TRIVIAL(info) << "An informational severity message";
        BOOST_LOG_TRIVIAL(warning) << "A warning severity message";
        BOOST_LOG_TRIVIAL(error) << "An error severity message";
        BOOST_LOG_TRIVIAL(fatal) << "A fatal severity message";
    }

The `BOOST_LOG_TRIVIAL` macro accepts a severity level and results in a stream-like object that supports insertion operator. As you can see, this library usage pattern is quite similar to what you would do with `std::cout`. However, the library offers a few advantages:

# The logging result is written to a text file, rather than the console.
# Besides the record message, each log record in the file contains a line number, a timestamp, thread identifier and severity level.
# It is safe to write logs from different threads concurrently.

It must be said that the macro, along with other similar macros provided by the library, is not the only interface that the library offers. It is possible to issue log records without using any macros at all.

[endsect]

[section:trivial_filtering Trivial logging with filters]

While severity levels can be used for informative purposes, you will normally want to apply filters to write only significant records to the file and ignore the rest. It is easy to do so by setting a global filter in the library core, like this:

    #include <boost/log/core.hpp>
    #include <boost/log/trivial.hpp>
    #include <boost/log/filters.hpp>

    void init()
    {
        logging::core::get()->set_filter
        (
            flt::attr< logging::trivial::severity_level >("Severity") >= logging::trivial::info
        );
    }

    int main(int, char*[])
    {
        init();

        BOOST_LOG_TRIVIAL(trace) << "A trace severity message";
        BOOST_LOG_TRIVIAL(debug) << "A debug severity message";
        BOOST_LOG_TRIVIAL(info) << "An informational severity message";
        BOOST_LOG_TRIVIAL(warning) << "A warning severity message";
        BOOST_LOG_TRIVIAL(error) << "An error severity message";
        BOOST_LOG_TRIVIAL(fatal) << "A fatal severity message";
    }

Now, if we run this code sample, the first two log records will be ignored, while the remaining four will pass on to the file.

[important Remember that the streaming expression is only executed if the record passed filtering. Don't specify business-critical calls in the streaming expression, as these calls may not get invoked if the record is filtered away.]

A few words must be said about the filter setup expression. Since we're setting up a global filter, we have to acquire the logging core instance. This is what `logging::core::get()` does - it returns a pointer to the core singleton. The `set_filter` method of the logging core sets the global filtering function.

The filter is built as a lambda expression. In our case, this expression consists of a single logical predicate, whose left argument is a placeholder that describes the attribute to be checked, and the right argument is the value to be checked against. The `flt::attr` is a template function that accepts attribute value type as its template parameter, and the attribute name as its first argument. In other words, the filter passes the record if it has attribute value with name "Severity" and type `severity_level`, and the value is not less than `info`. Pretty easy, isn't it?

It is possible to build more complex filters as lambda expressions, combining logical predicates like this with each other, or even define your own function that would act as a filter. More on this is said [link log.detailed.filters here].

[endsect]

[section:sinks Setting up sinks]

Sometimes trivial logging doesn't provide enough flexibility. For example, one may want a more sophisticated logic of log processing, rather than simply storing it into a file. In order to customize this, you have to construct logging sinks and register them with the logging core. This should normally be done only once somewhere in the startup code of your application.

[heading File logging unleashed]

As a starting point, here is how you would initialize logginig into a file, similarly to the trivial logging:

    void init()
    {
        logging::init_log_to_file("sample.log");
        logging::core::get()->set_filter
        (
            flt::attr< logging::trivial::severity_level >("Severity") >= logging::trivial::info
        );
    }

    // We'll skip the "main" function for now

The added piece is a call to the `init_log_to_file` function. As the name implies, the function initializes a logging sink that stores log records into a text file. The function also accepts a number of customization options, such as the rotation interval and size limits. For instance:

    void init()
    {
        logging::init_log_to_file
        (
            keywords::file_name = "sample_%N.log",                  // file name pattern
            keywords::rotation_size = 10 * 1024 * 1024,             // rotate files every 10 MiB...
                                                                    // ...or at midnight
            keywords::time_based_rotation = sinks::file::rotation_at_time_point(0, 0, 0),
            keywords::format = "[%TimeStamp%]: %_%"                 // log record format
        );

        logging::core::get()->set_filter
        (
            flt::attr< logging::trivial::severity_level >("Severity") >= logging::trivial::info
        );
    }

You can see that the options are passed to the function in the named form. This approach is taken in many places of the library. You'll get used to it. The meaning of the parameters is mostly self-explaining, and is documented in this manual (see [link log.detailed.sink_backends.text_file here] for what regards the text file sink). This and other convenience initialization functions are described in [link log.detailed.utilities.init.convenience this] section.

[note You can register more than one sink. Each sink will process log records independently from others. In particular this means that you can use trivial logging and additionally register one or more sinks as shown above. All sinks will receive log records as you emit them.]

[heading Sinks in depth: More sinks]

If you don't want to go into details, you can skip this section and continue from the next one. Otherwise, if you need more comprehensive control over sink configuration, or want to use different sinks, you may consider registering them manually.

In the simplest form, the call to the `init_log_to_file` function in the section above is equivalent to this:

    void init()
    {
        // Construct the sink
        typedef sinks::synchronous_sink< sinks::text_ostream_backend > text_sink;
        boost::shared_ptr< text_sink > pSink = boost::make_shared< text_sink >();

        // Add a stream to write log to
        pSink->locked_backend()->add_stream(
            boost::make_shared< std::ofstream >("sample.log"));

        // Register the sink in the logging core
        logging::core::get()->add_sink(pSink);
    }

Ok, the first thing you may have noticed about sinks is that they are composed of two classes: the frontend and the backend. The frontend (which is the `synchronous_sink` class template in the snippet above) is responsible for various common tasks for all sinks, such as thread synchronization model and filtering. The backend (the `text_ostream_backend` class above) implements everything specific to the sink, such as text formatting and writing to a file in this case. The library provides a number of frontends and backends that can be used with each other out of the box.

The `synchronous_sink` class template above indicates that the sink is synchronous, that is, it allows several threads to log simultaneously and will block in case of contention. This means that the backend `text_ostream_backend` need not worry about multithreading at all. There are other sink frontends available, you can read more about them [link log.detailed.sink_frontends here].

The `text_ostream_backend` class writes formatted log records into STL-compatible streams. We have used a file stream above but we could have used any type of stream. For example, adding output to console could look as follows:

    #include <boost/log/utility/empty_deleter.hpp>

    // We have to provide an empty deleter to avoid destroying the global stream object
    boost::shared_ptr< std::ostream > pStream(&std::clog, logging::empty_deleter());
    pSink->locked_backend()->add_stream(pStream);

The `text_ostream_backend` supports adding several streams. In that case its output will be duplicated to all added streams. This may be useful to duplicate output to console and file, since all the filtering, formatting and other overhead of the library happen only once per record for the sink.

[note Please note the difference between registering several distinct sinks and registering one sink with several target streams. While the former allows independently customizing output to each sink, the latter would work considerably faster if such customization is not needed. This feature is specific to this particular backend.]

The library provides a number of [link log.detailed.sink_backends backends] that provide different log processing logic. For instance, by specifying a [link log.detailed.sink_backends.syslog syslog] backend you can send log records over the network to the syslog server, or by setting up a [link log.detailed.sink_backends.event_log Windows NT event log] backend you can monitor your application run time by the standard Windows tools.

The last thing worth noting here is the `locked_backend` member function call to access the sink backend. It is used to get thread-safe access to the backend and is provided by all sink frontends. This function returns a smart-pointer to the backend and as long as it exists the backend is locked (which means even if another thread tries to log and the log record is passed to the sink, it will not be logged until you release the backend). The only exception is the `unlocked_sink` frontend which does not synchronize at all and simply returns an unlocked pointer to the backend.

[endsect]

[section:formatters Log record formatting]

Returning to one of the examples in previous tutorial sections:

    void init()
    {
        logging::init_log_to_file
        (
            keywords::file_name = "sample_%N.log",
            keywords::rotation_size = 10 * 1024 * 1024,
            keywords::time_based_rotation = sinks::file::rotation_at_time_point(0, 0, 0),
            keywords::format = "[%TimeStamp%]: %_%"
        );

        logging::core::get()->set_filter
        (
            flt::attr< logging::trivial::severity_level >("Severity") >= logging::trivial::info
        );
    }

One may wonder how to specify log record formatting rules. In the case of the `init_log_to_file` function, this is what the `format` parameter for. If you prefer to set up sinks manually, most sink backends provide the `set_formatter` member function for this purpose.

The format can be specified in a number of ways, described further.

[heading Lambda-style formatters]

You can create a formatter with a lambda-style expression like this:

    void init()
    {
        logging::init_log_to_file
        (
            keywords::file_name = "sample_%N.log",
            // This makes the sink to write log records that look like this:
            // 1: <normal> A normal severity message
            // 2: <error> An error severity message
            keywords::format =
            (
                fmt::stream
                    << fmt::attr< unsigned int >("LineID")
                    << ": <" << fmt::attr< logging::trivial::severity_level >("Severity")
                    << "> " << fmt::message()
            )
        );
    }

Here the `stream` is a placeholder for the stream to format the record in. Other insertion arguments, such as `attr` and `message`, are manipulators that define what should be stored in the stream. The `message` manipulator is a bit special since, unlike all other manipulators, it writes a preformatted message acquired from the logger, not an attribute value. There are other [link log.detailed.formatters formatter manipulators] that provide advanced support for date, time and other types.

Some manipulators may accept additional arguments that customize their behavior. Most of these arguments are named and can be passed in __boost_parameter__ style. For example, `attr` supports a format specifier in a printf-style string. For a change, let's see how it's done when manually initializing sinks:

    void init()
    {
        typedef sinks::synchronous_sink< sinks::text_ostream_backend > text_sink;
        boost::shared_ptr< text_sink > pSink = boost::make_shared< text_sink >();

        pSink->locked_backend()->add_stream(
            boost::make_shared< std::ofstream >("sample.log"));

        pSink->locked_backend()->set_formatter
        (
            fmt::stream
                   // line id will be written in hex, 8-digits, zero-filled
                << fmt::attr< unsigned int >("LineID", keywords::format = "%08x")
                << ": <" << fmt::attr< logging::trivial::severity_level >("Severity")
                << "> " << fmt::message()
        );

        logging::core::get()->add_sink(pSink);
    }

For the reference of the supported arguments see the reference of the corresponding manipulator. More manipulators are described in the [link log.detailed.formatters Detailed features description] section.

[heading Boost.Format-style formatters]

As an alternative, you can define formatters with with a syntax similar to __boost_format__. The same formatter as described above can be written as follows:

    void init()
    {
        typedef sinks::synchronous_sink< sinks::text_ostream_backend > text_sink;
        boost::shared_ptr< text_sink > pSink = boost::make_shared< text_sink >();

        pSink->locked_backend()->add_stream(
            boost::make_shared< std::ofstream >("sample.log"));

        // This makes the sink to write log records that look like this:
        // 00000001: <normal> A normal severity message
        // 00000002: <error> An error severity message
        pSink->locked_backend()->set_formatter
        (
            fmt::format("%1%: <%2%> %3%")
                % fmt::attr< unsigned int >("LineID", keywords::format = "%08x")
                % fmt::attr< logging::trivial::severity_level >("Severity")
                % fmt::message()
        );

        logging::core::get()->add_sink(pSink);
    }

The `format` placeholder accepts the format string with positional specification of all arguments being formatted. Note that only positional format is currently supported. The same format specification can be used with the `init_log_to_file` and similar functions.

[heading String templates as formatters]

In some contexts textual templates are accepted as formatters. In this case library initialization support code is invoked in order to parse the template and reconstruct the appropriate formatter. There are a number of caveats to keep in mind when using this approach, but here it will suffice to just briefly describe the template format.

    void init()
    {
        logging::init_log_to_file
        (
            keywords::file_name = "sample_%N.log",
            keywords::format = "[%TimeStamp%]: %_%"
        );

        logging::core::get()->set_filter
        (
            flt::attr< logging::trivial::severity_level >("Severity") >= logging::trivial::info
        );
    }

Here, the `format` parameter accepts such a format template. The template may contain a number of placeholders enclosed with percent signs (`%`). Each placeholder must contain an attribute value name to insert instead of the placeholder. The `%_%` placeholder is special as it will be replaced with the logging record message.

[note Textual format templates are not accepted by sink backends in the `set_formatter` method. In order to parse textual template into a formatter function one has to call `parse_formatter` function. See [link log.detailed.utilities.init.filter_formatter here] for more details.]

[heading Custom formatting functons]

You can add a custom formatter to a sink backend that supports formatting. The formatter is actually a function object that supports the following signature:

    void (std::basic_ostream< CharT >& strm, logging::basic_record< CharT > const& rec);

Here `CharT` is the character type that is used with the library. The formatter will be invoked whenever a log record `rec` passes filtering and is to be stored in log. The formatted record should be composed by insertion into STL-compatible output stream `strm`. Here's an example of a custom formatter function usage:

    void my_formatter(std::ostream& strm, logging::record const& rec)
    {
        namespace lambda = boost::lambda;

        unsigned int line_id;
        if (logging::extract< unsigned int >(
            "LineID", rec.attribute_values(), lambda::var(line_id) = lambda::_1))
        {
            strm << line_id << ": ";
        }

        logging::trivial::severity_level severity;
        if (logging::extract< logging::trivial::severity_level >(
            "Severity", rec.attribute_values(), lambda::var(severity) = lambda::_1))
        {
            strm << "<" << severity << "> ";
        }

        strm << rec.message();
    }

    void init()
    {
        typedef sinks::synchronous_sink< sinks::text_ostream_backend > text_sink;
        boost::shared_ptr< text_sink > pSink = boost::make_shared< text_sink >();

        pSink->locked_backend()->add_stream(
            boost::make_shared< std::ofstream >("sample.log"));

        pSink->locked_backend()->set_formatter(&my_formatter);

        logging::core::get()->add_sink(pSink);
    }

[endsect]

[section:sources Creating loggers and writing logs]

[heading Dedicated logger objects]

Now that we have defined where and how the log is to be stored, it's time to go on and try logging. In order to do this one has to create a logging source. This would be a logger object in our case and it is as simple as that:

    src::logger lg;

Note that unlike sinks, sources need not be registered anywhere, since they interact directly with logging core. Also note that there are two versions of loggers provided by the library: the thread-safe ones and the non-thread-safe ones. For the non-thread-safe loggers it is safe for different threads to write logs through different instances of loggers and thus there should be a separate logger for each thread that writes logs. The thread-safe counterparts may be accessed from different threads concurrently, but this would involve locking and may slow things down in case of intense logging. The thread-safe logger types have the `_mt` suffix in their name.

Regardless of the thread safety, all loggers provided by the library are default and copy-constructible and support swapping, so there should be no problem in making a logger a member of your class. As you will see later, such approach can give you additional benefits.

The library provides a number of loggers with different features, such as severity and channel support. These features may be combined with each other in order to construct more complex loggers. See [link log.detailed.sources here] for more datails.

[heading Global logger objects]

In case you cannot put a logger into your class (suppose you don't have one), the library provides a way of declaring global loggers like this:

    BOOST_LOG_DECLARE_GLOBAL_LOGGER(my_logger, src::logger_mt)

Here `my_logger` is a user-defined tag name that will be used later to retrieve the logger instance and `logger_mt` is the logger type. Any logger type provided by the library or defined by the user can be used in such declaration. However, since the logger will have a single instance, you will normally want to use thread-safe loggers in a multithreaded application as global ones.

In case you want to pass some arguments to the logger on construction, you can use the following macro:

    BOOST_LOG_DECLARE_GLOBAL_LOGGER_CTOR_ARGS(my_logger, src::logger_mt, (arg1)(arg2)(arg3))

or even write the initialization code yourself:

    BOOST_LOG_DECLARE_GLOBAL_LOGGER_INIT(my_logger, src::logger_mt)
    {
        // do something on logger initialization and return logger instance
        return src::logger_mt();
    }

You can have such declaration in either a header or a compiled cpp unit. You can even have it in different modules of your application, however, the declaration should be exactly the same in all places, including the definition of the logger type (`logger_mt` in this case) and all symbol bindings within the logger initialization body.

Later on you can acquire the logger like this:

    src::logger_mt& lg = get_my_logger();

or like this:

    src::logger_mt& lg = my_logger::get();

In any case, the `lg` will reference to the one and only instance of the logger throughout the application, even if the application consists of multiple modules.

[heading Writing logs]

No matter what kind of logger you use (class member or global, thread-safe or not), to write a log record into a logger you could write something like this:

    logging::record rec = lg.open_record();
    if (rec)
    {
        rec.message() = "Hello world!";
        lg.push_record(rec);
    }

Here the `open_record` function call determines if the record to be constructed is going to be consumed by at least one sink. Filtering is applied at this stage. If the record is to be consumed, the function returns a valid record object, and one may fill in the record message string. After that the record processing can be completed with the call to `push_record`.

Of course, the above syntax can easily be wrapped in a macro and, in fact, users are encouraged to write their own macros instead of using the C++ logger interface directly. The log record above can be written like this:

    #include <boost/log/sources/record_ostream.hpp>

    BOOST_LOG(lg) << "Hello, World!";

Looks a bit shorter, doesn't it? The `BOOST_LOG` macro, along with other similar ones, is defined by the library. It automatically provides an STL-like stream in order to format the message with ordinary insertion expressions. Having all that code written, compiled and executed you should be able to see the "Hello, World!" record in the "sample.log" file.

[endsect]

[section:attributes Adding more information to log: Attributes]

If, while reading the previous sections, you wondered where these "LineID" and "Severity" things came from, the answer is here.

Each log record can have a number of attributes attached. Attributes can contain any essental information about the conditions in which the log record occurred, such as position in the code, executable module name, current date and time, or any piece of data relevant to your particular application and execution environment. An attribute may behave as a value generator, in which case it would return a different value for each log record it's involved in. As soon as the attribute generates the value, the latter becomes independent from the creator and can be used by different filters, formatters and sinks. But in order to do so one has to know the type of the value, or at least what types it may have. There are a number of commonly used attributes implemented in the library, you can find the types of their values in the documentation.

Aside from that, as noted in the [link log.design Design overview] section, there are three possible scopes of attributes: source-specific, thread-specific and global. When a log record is made, attribute values from these three sets are accumulated into a single view and passed to sinks, so where the attribute was registered makes no difference for them. Any attribute can be registered in any scope. When registered, an attribute is given a unique name in order to make it possible to search for it. If it happens that the same named attribute is found in several scopes, the attribute from the most specific scope is taken into consideration in any further processing, including filtering and formatting. Such behavior makes it possible to override global or thread-scoped attributes with the ones registered in your local logger, thus reducing thread interference.

Getting back to our tutorial, "LineID" and "Severity" are attribute names. These attributes are registered by certain parts of the library, such as loggers and trivial logging setup code. Below is the description of the attribute registration process.

[heading Commonly used attributes]

There are attributes that are likely to be used in nearly any application. For instance, log record counter and a time stamp. They can be added with a single function call:

    logging::add_common_attributes();

With this call attributes "LineID", "TimeStamp", "ProcessID" and "ThreadID" are registered globally. The "LineID" attribute is a counter that increments for each record being made, the first record gets identifier 1. The "TimeStamp" attribute always yelds the current time (i.e. the time when the log record is created, not the time it was written to a sink). The last two attributes identify the process and the thread in which every log record is emitted.

[important In single-threaded builds the "ThreadID" attribute is not registered.]

[tip The trivial logging support code calls `add_common_attributes` internally in order to set up attributes available by default. If you use trivial logging, you don't have to call this function yourself.]

This function is one of the several convenience functions described [link log.detailed.utilities.init.convenience here].

Some attrubutes are registered automatically on loggers construction. For example, `severity_logger` registers a source-specific attribute "Severity" which can be used to add a level of emphasis for different log records. For example:

    // We define our own severity levels
    enum severity_level
    {
        normal,
        notification,
        warning,
        error,
        critical
    };

    // The logger implicitly adds a source-specific attribute 'Severity'
    // of type 'severity_level' on construction
    src::severity_logger< severity_level > slg;

    BOOST_LOG_SEV(slg, normal) << "A regular message";
    BOOST_LOG_SEV(slg, warning) << "Something bad is going on but I can handle it";
    BOOST_LOG_SEV(slg, critical) << "Everything crumbles, shoot me now!";

[tip You can define your own formatting rules for the severity level by defining `operator <<` for this type. See [link log.detailed.formatters.attr this] section for more details.]

The `BOOST_LOG_SEV` macro acts pretty much like `BOOST_LOG` except that it takes an additional argument for the `open_record` method of the logger. The `BOOST_LOG_SEV` macro can be replaced with this equivalent:

    logging::record rec = lg.open_record(keywords::severity = normal);
    if (rec)
    {
        rec.message() = "A regular message";
        lg.push_record(rec);
    }

You can see here that the `open_record` can take named arguments. Some logger types provided by the library have support for such additional parameters and this approach can certainly be used by users when writing their own loggers.

[tip If you wonder if it is possible to define formatting rules for your custom severity level type (or any other type for that matter), then yes, it is. The simplest way to do it is to define `operator <<` for your type and then use the `attr` formatter that was described earlier. See [link log.detailed.formatters.attr here] for more details.]

[heading More attributes]

Let's see what's under the hood of that `add_common_attributes` function we used in the simple form section. It might look something like this:

    void add_common_attributes()
    {
        boost::shared_ptr< logging::core > pCore = logging::core::get();
        pCore->add_global_attribute(
            "LineID", boost::make_shared< attrs::counter< unsigned int > >(1));
        pCore->add_global_attribute(
            "TimeStamp", boost::make_shared< attrs::local_clock >());

        // other attributes skipped for brevity
    }

Here the `counter` and `local_clock` components are attribute classes, they derive from the common attribute interface `attribute`. The library provides a number of other [link log.detailed.attributes attribute classes], including the `functor` attribute that calls some functional object on value acquisition. For example, we can in a similar way register a `named_scope` attrubute:

    pCore->add_global_attribute(
        "Scope", boost::make_shared< attrs::named_scope >());

This will give the ability to store scope names in log for every log record the application makes.

Logger-specific attributes are no less useful than global ones. Severity levels and channel names are the most obvious candidates to be implemented on the source level. Nothing prevents you from adding more attributes to your loggers, like this:

    lg.add_attribute("Tag", boost::make_shared< attrs::constant< std::string > >("My tag value"));

Now all log records made through this logger will be tagged with the specific attribute. This attribute value may be used later in filtering and formatting.

Another good use of attributes is the ability to mark log records made by different parts of application in order to highlight activity related to a single process. One may even implement a rough profiling tool to detect performance bottlenecks. For example:

    void foo()
    {
        BOOST_LOG_SCOPED_THREAD_ATTR("Timeline", attrs::timer);
        bar();
    }

Now every log record made from the `bar` function, or any other function it calls, will contain the "Timeline" attribute with a high precision time duration passed since the attribute was registered. Based on these readings, one may detect which parts of the code require more or less time to execute. The "Timeline" attribute will be unregistered upon leaving the scope of function `foo`.

See the [link log.detailed.attributes Attributes] section for detailed description of attributes provided by the library.

[endsect]

[endsect]
